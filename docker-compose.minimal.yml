version: '3.8'

services:
  voice-ai-service:
    build:
      context: .
      dockerfile: Dockerfile.optimized
    container_name: python-voice-ai-minimal
    ports:
      - "4000:4000"
    environment:
      # Application Settings
      - APP_NAME=AI Voice Service
      - APP_VERSION=1.0.0
      - DEBUG=false
      - HOST=0.0.0.0
      - PORT=4000
      
      # AI API Keys (REQUIRED)
      - GROQ_API_KEY=${GROQ_API_KEY}
      
      # STT Configuration
      - WHISPER_MODEL=base
      - WHISPER_DEVICE=cpu
      - WHISPER_LANGUAGE=en
      
      # AI Configuration
      - AI_PROVIDER=groq
      - AI_MODEL=llama-3.1-8b-instant
      - AI_MAX_TOKENS=150
      - AI_TEMPERATURE=0.7
      - AI_TIMEOUT=30
      
      # TTS Configuration
      - TTS_PROVIDER=edge
      - TTS_VOICE=en-US-AriaNeural
      - TTS_RATE=+0%
      - TTS_VOLUME=+0%
      
      # WebSocket Settings
      - WS_HEARTBEAT_INTERVAL=30
      - WS_MAX_CONNECTIONS=100
      - WS_MESSAGE_QUEUE_SIZE=100
      
      # Audio Processing
      - AUDIO_SAMPLE_RATE=16000
      - AUDIO_CHANNELS=1
      - AUDIO_FORMAT=wav
      
      # Performance
      - MAX_WORKERS=4
      - REQUEST_TIMEOUT=60
      - MAX_CONCURRENT_REQUESTS=10
      
      # Logging
      - LOG_LEVEL=INFO
      - LOG_FORMAT=json
      - LOG_DIR=logs
      
      # Security
      - CORS_ORIGINS_RAW=*
      - API_KEY_HEADER=X-API-Key
      - ENABLE_AUTH=false
      
      # Monitoring
      - ENABLE_METRICS=false
      - METRICS_PORT=9090
    
    volumes:
      # Persist logs
      - ./logs:/app/logs
      # Optional: Mount models directory if you want to persist Whisper models
      - ./models:/app/models
    
    restart: unless-stopped
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    
    networks:
      - voice-ai-network

networks:
  voice-ai-network:
    driver: bridge

volumes:
  voice-ai-logs:
    driver: local
